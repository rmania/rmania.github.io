---
title: "Why many A.I. projects will not get adopted"
date: 2020-05-31
tags: [adoption, AI, projects, machine learning, advanced analytics]
header:
  image: "/images/logos/ai_logo.png"
excerpt: "Artifical intelligence, adoption"
mathjax: "true"
---

# Translating A.I. introduction

### coining the terms

Throughout this blog I will use the terms A.I. and ML, Advanced Analytics and Data Science. 

### Intro

Many companies are developing machine learning models for internal use. Be it with dedicated internally placed data science teams (centrally placed or somewhat decentralized across silos) or by some degree of outsourcing, external hiring or a hybrid format. Many companies though are struggling to bridge the gap to practical deployments in order to generate real business impact. AI is rapidly expanding into new applications and industries, and research is making advancements. Yet building successful projects is still difficult. 

### Some 2020 figures

In 2019 Gartner predicted that “through 2020, 80 percent of AI projects will remain alchemy, run by wizards whose talents will not scale in the organization”. "Through 2022, only 20% of analytic insights will deliver business outcomes" [Gartner blog](https://blogs.gartner.com/andrew_white/2019/01/03/our-top-data-and-analytics-predicts-for-2019/). 

Some of the main takeaways of a broad "2020 State of Enterprise Machine Learning survey" conducted by Algorithmia (a marketplace for algorithms as they call themselves), state that there is a growing number of companies that are entering early stages of ML development, but challenges in deployment, scaling, versioning, and other sophistication efforts still hinder companies and organizations from extracting value from their ML investments. As a result, they foresee a boom in the number of ML companies providing specific services to overcome these obstacles in the near term. A couple of their main findings for 2020 are worth mentioning: 

1) Machine learning operationalization (having a deployed ML lifecycle) is still underdeveloped but maturing across all industries with software and IT firms leading the charge.
2) main challenges people face when developing ML capabilities are scale, version control, model
reproducibility, and aligning stakeholders. There is much more to it and you can find the report [here]([https://info.algorithmia.com/hubfs/2019/Whitepapers/The-State-of-Enterprise-ML-2020/Algorithmia_2020_State_of_Enterprise_ML.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9Vd4xkmSNgZRdtOAxrGPWwvHj0DE9xCiktWf-bS0o6m80dXV_jV20L-cbkLq6DzbxiK7hL](https://info.algorithmia.com/hubfs/2019/Whitepapers/The-State-of-Enterprise-ML-2020/Algorithmia_2020_State_of_Enterprise_ML.pdf?utm_campaign=The Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9Vd4xkmSNgZRdtOAxrGPWwvHj0DE9xCiktWf-bS0o6m80dXV_jV20L-cbkLq6DzbxiK7hL))

This report also states that many companies haven't figured out how to realize their AI ambitions. Although AI budgets are on the rise, only 22 percent of companies using machine learning have successfully deployed a model, the study found. There are tons of other figures but they all state the alarmingly high rates of lost potential. In a blog post that received some buzz end of 2018, Giovanni Lanzani, director of learning and development at GoDataDriven wrote an article about wasting money with data science. [(link here)](https://godatadriven.com/blog/wasting-money-with-data-science/) that describes this well. It's still kind of the dirty secret of Data Science.

But what are the guidelines, frameworks and best practices to overcome this? Should data science capabilities be siloed throughout the company? Is a central innovation hub that can iterate quickly and build rapid prototypes, helping to standardize ML efforts, a good idea? They can often vet new technologies quickly, ensuring their companies keep at the bleeding edge of technological development. It is to be anticipated that these kind of centralized focus on ML and AI technologies may just turn lead into gold. It all depends on the organization and the use-case off course but it may be very much possible to distill out some key components. 

For instance establishing a strong bridge between the Advanced Analytics teams and the business can only enhance the adoption of ML-projects as is the establishment of effective practices and processes around designing, building, and deploying models. 

So in these series of blog posts I will deep-dive several remedies for the above-mentioned challenges. In a first attempt I will sub-divide the themes up into the following (all to be found under the section "Translating A.I. posts" [here](https://rmania.github.io/translating_ai/):

- **The A.I. strategy** - _what core components should it contain and how to align for maximum impact._

- **ML/A.I pipelines and frameworks** - _the tech (including platforms), best practices and frameworks that speed up and facilitate well-engineered ML pipelines._

- **Model deployment: scalability and reproducibility** - _architectures, best practices, and some optimizations that are useful when doing machine learning at scale._

- **Overcoming organizational challenges** - _how to get "the business" lines involved during the projects and make them also responsible for the end-result_. 

- **Translating A.I.** - _we will specifically look at new roles that build bridges between the data science teams and the business: the A.I. translator_.

  

Furthermore I will dive into interesting questions that I perceive as being undervalued or not receiving the attention it should. 

* _how can we really play the monetization card. What are some gotchas when wanting to claim your ML model made actual money. How to prove it?_
* **explainable A.I.** 

---

footer:
  image: "/images/logos/ai_logo.png"

---




